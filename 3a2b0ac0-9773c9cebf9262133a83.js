"use strict";(self.webpackChunkgatsby_starter_hello_world=self.webpackChunkgatsby_starter_hello_world||[]).push([[974],{6325:function(t,e,s){s.d(e,{W:function(){return y}});var n=s(8081),o=s(1944),i=s(588),r=s(9897),a=s(2931),u=s(1977),h=s(7538),l=s(1653),c=s(7385),p=s(69),d=s(4396),f=s(163);class y extends f.mh{constructor(t){if(super({}),this.containerNodes=new Set,this.name=t.name,null==this.name){const t=this.getClassName().toLowerCase();this.name=(0,o.s)(t)}if(this.supportsMasking=!1,this.trainable_=!0,Array.isArray(t.inputs)?this.inputs=t.inputs.slice():this.inputs=[t.inputs],Array.isArray(t.outputs)?this.outputs=t.outputs.slice():this.outputs=[t.outputs],a.Tw(this.inputs).length!==this.inputs.length)throw new i.nu(`The list of inputs passed to the model is redundant. All inputs should only appear once. Found: ${this.inputs.map((t=>t.name))}`);a.Tw(this.outputs).length!==this.outputs.length&&console.warn(`The list of outputs passed to the model is redundant. All outputs should only appear once. Found: ${this.outputs.map((t=>t.name))}`),this.inputLayers=[],this.inputLayersNodeIndices=[],this.inputLayersTensorIndices=[],this.outputLayers=[],this.outputLayersNodeIndices=[],this.outputLayersTensorIndices=[],this.layers=[],this.internalContainerRefs=[];for(const o of this.outputs){const t=o.sourceLayer,e=o.nodeIndex,s=o.tensorIndex;this.outputLayers.push(t),this.outputLayersNodeIndices.push(e),this.outputLayersTensorIndices.push(s)}for(const o of this.inputs){const t=o.sourceLayer,e=o.nodeIndex,s=o.tensorIndex;a.hu(0===e,"input layer has >1 nodes"),a.hu(0===s,"input layer has >1 tensors"),this.inputLayers.push(t),this.inputLayersNodeIndices.push(e),this.inputLayersTensorIndices.push(s)}this.inputNames=[],this.outputNames=[],this.feedInputShapes=[],this.feedInputNames=[],this.feedOutputNames=[];for(let o=0;o<this.inputLayers.length;o++){const e=this.inputLayers[o];if(!(e instanceof d.l))throw new TypeError(`Input layers to a LayersModel must be InputLayer objects. Received inputs: ${t.inputs}. Input ${o} (0-based) originates from layer type ${e.getClassName()}.`);this.inputNames.push(e.name),this.feedInputShapes.push(e.batchInputShape),this.feedInputNames.push(e.name)}for(const o of this.outputLayers)this.outputNames.push(o.name);this.internalInputShapes=this.inputs.map((t=>t.shape)),this.internalOutputShapes=this.outputs.map((t=>t.shape));const e={},s={},n={},r={},u={},h=[],l=(t,e,s,n,o,r)=>{null!=n&&null!=o&&null!=r||(n=t.sourceLayer,o=t.nodeIndex,r=t.tensorIndex);const a=n.inboundNodes[o];if(-1!==s.indexOf(a))throw new i.LH(`The tensor ${t.name} at layer "${n.name}" is part of a cycle.`);if(-1!==e.indexOf(a))return;this.containerNodes.add(y.nodeKey(n,o)),n.id in u||(u[n.id]=Object.keys(u).length),-1===s.indexOf(a)&&s.push(a);const c=a.inboundLayers.length;for(let i=0;i<c;i++){const t=a.inputTensors[i],n=a.inboundLayers[i],o=a.nodeIndices[i],r=a.tensorIndices[i];l(t,e,s,n,o,r)}for(e.push(a);s.indexOf(a)>=0;)s.splice(s.indexOf(a),1);h.push(a)},c=[],p=[];for(const o of this.outputs)l(o,c,p);const m=h.slice().reverse();for(const o of m){s[o.id]=o,o.id in e||(e[o.id]=0);let t=e[o.id];const i=null==n[o.outboundLayer.id]?0:n[o.outboundLayer.id];t=Math.max(t,i),n[o.outboundLayer.id]=t,r[o.outboundLayer.id]=o.outboundLayer,e[o.id]=t;for(let n=0;n<o.inboundLayers.length;n++){const i=o.inboundLayers[n],r=o.nodeIndices[n],a=i.inboundNodes[r],u=null==e[a.id]?0:e[a.id];e[a.id]=Math.max(t+1,u),s[a.id]=a}}const g={};for(const o in e){const t=e[o];t in g||(g[t]=[]),g[t].push(s[o])}const b={};for(const o in n){const t=n[o];t in b||(b[t]=[]),b[t].push(r[o])}let L=Object.keys(b).map((t=>parseInt(t,10))).sort(a.L7);this.layers=[];for(const o of L){const t=b[o];t.sort(((t,e)=>{const s=u[t.id],n=u[e.id];return s<n?-1:s>n?1:0}));for(const e of t)e instanceof y&&this.internalContainerRefs.push(e),this.layers.push(e)}this.layersByDepth=b,L=Object.keys(g).map((t=>parseInt(t,10))).sort(a.L7);const w=this.inputs.slice(),N=[];for(const o of L)for(const t of g[o]){const e=t.outboundLayer;if(null!=e){for(const s of t.inputTensors)if(-1===w.indexOf(s))throw new i.LH(`Graph disconnected: cannot obtain value for tensor ${s} at layer "${e.name}". The following previous layers were accessed without issue: ${N}`);for(const e of t.outputTensors)w.push(e);N.push(e.name)}}this.nodesByDepth=g;const I=this.layers.map((t=>t.name));for(const o of I){const t=I.filter((t=>t===o)).length;if(1!==t)throw new i.LH(`The name "${o}" is used ${t} times in the model. All layer names should be unique. Layer names: `+JSON.stringify(I))}this.outboundNodes=[],this.inboundNodes=[],new f.NB({outboundLayer:this,inboundLayers:[],nodeIndices:[],tensorIndices:[],inputTensors:this.inputs,outputTensors:this.outputs,inputMasks:this.inputs.map((t=>null)),outputMasks:this.outputs.map((t=>null)),inputShapes:this.inputs.map((t=>t.shape)),outputShapes:this.outputs.map((t=>t.shape))}),this.built=!0,this._refCount=1}assertNotDisposed(){if(0===this._refCount)throw new Error(`Container '${this.name}' is already disposed.`)}dispose(){this.assertNotDisposed();const t={refCountAfterDispose:null,numDisposedVariables:0};if(0==--this._refCount){for(const e of this.layers)t.numDisposedVariables+=e.dispose().numDisposedVariables;for(const e of this.internalContainerRefs)t.numDisposedVariables+=e.dispose().numDisposedVariables}return t.refCountAfterDispose=this._refCount,t}get trainable(){return this.trainable_}set trainable(t){this.layers.forEach((e=>{e._trainableWeights.forEach((e=>e.trainable=t))})),this.trainable_=t}get trainableWeights(){if(this._trainableWeights.length>0)throw new i.nu("Container instance unexpectedly contains _trainableWeights.The trainable weights of a Container are a union of the trainable weights of its consituent Layers. Its own _trainableWeights must remain an empty Array.");if(!this.trainable)return[];let t=[];for(const e of this.layers)t=t.concat(e.trainableWeights);return t}get nonTrainableWeights(){const t=[];for(const e of this.layers)t.push(...e.nonTrainableWeights);if(!this.trainable){const e=[];for(const t of this.layers)e.push(...t.trainableWeights);return e.concat(t)}return t}get weights(){return this.trainableWeights.concat(this.nonTrainableWeights)}loadWeights(t,e=!0){const s={};let n=0;const o=(t=>{const e=Object.keys(t);if(0===e.length)return!1;const s=e[0].split("/");return!isNaN(parseInt(s[s.length-1],10))})(t);o&&this.parseWeights(t);for(const a of this.layers)for(const[t,e]of a.weights.entries()){const r=o?`${e.name.split("/").slice(0,-1).join("/")+"/"}${t}`:e.originalName;if(null!=s[r])throw new i.nu(`Duplicate weight name: ${r}`);s[r]=e,n++}const r=[];for(const a in t){let n=a;if(null==s[a]){const t=a.split("/");n=t.slice(0,-2).concat([t[t.length-1]]).join("/")}if(null!=s[n])r.push([s[n],t[a]]);else if(e)throw new i.nu(`Provided weight data has no target variable: ${a}`);delete s[n]}if(e){const t=[];for(const e in s)t.push(e);if(t.length>0)throw new i.nu(`${t.length} of ${n} weights are not set: ${t}`)}(0,l.zb)(r)}parseWeights(t){for(const e in Object.keys(t)){const s=e.split("/"),n=["vars","layer_checkpoint_dependencies"],o=s.map((t=>t.startsWith("_")?t.slice(1):t)).filter((t=>!n.includes(t))).join("/");o!==e&&(t[o]=t[e],delete t[e])}}updatedConfig(){const t=this.getConfig(),e={};return e.className=this.getClassName(),e.config=t,e.kerasVersion=`tfjs-layers ${c.i}`,e.backend="TensorFlow.js",e}toJSON(t,e=!0){const s=(0,u.q)(this.updatedConfig());return e?JSON.stringify(s):s}call(t,e){return(0,n.tidy)((()=>{t=a.zZ(t);const s=new p.l2;for(let e=0;e<this.inputs.length;++e)s.add(this.inputs[e],t[e]);return(0,p.ht)(this.outputs,s,e)}))}computeMask(t,e){return(0,n.tidy)((()=>{let s;return t=a.zZ(t),s=null==e?a.JE(null,t.length):a.zZ(e),this.runInternalGraph(t,s)[1]}))}computeOutputShape(t){const e=h.x6(t);if(e.length!==this.inputLayers.length)throw new i.nu(`Invalid inputShape argument ${t}: model has ${this.inputLayers.length} tensor inputs.`);const s={};for(let i=0;i<e.length;i++){const t=this.inputLayers[i],n=e[i];s[t.name+"_0_0"]=n}const n=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(a.L7);if(n.length>1)for(const i of n){const t=this.nodesByDepth[i];for(const e of t){const t=e.outboundLayer;if(-1!==this.inputLayers.map((t=>t.id)).indexOf(t.id))continue;const n=[];for(let a=0;a<e.inboundLayers.length;a++){const t=e.inboundLayers[a],o=e.nodeIndices[a],i=e.tensorIndices[a],r=s[`${t.name}_${o}_${i}`];n.push(r)}const o=t.computeOutputShape(a.Bq(n)),i=h.x6(o),r=t.inboundNodes.indexOf(e);for(let e=0;e<i.length;e++){s[`${t.name}_${r}_${e}`]=i[e]}}}const o=[],r=[];for(let i=0;i<this.outputLayers.length;i++){const t=this.outputLayers[i],e=this.outputLayersNodeIndices[i],s=this.outputLayersTensorIndices[i],n=`${t.name}_${e}_${s}`;r.push(n)}for(let i=0;i<r.length;i++){const t=r[i];a.hu(t in s),o.push(s[t])}return a.Bq(o)}runInternalGraph(t,e){null==e&&(e=a.JE(null,t.length));const s={};for(let i=0;i<this.inputs.length;++i){const n=this.inputs[i],o=t[i],r=e[i];s[n.id]=[o,r]}const n=Object.keys(this.nodesByDepth).map((t=>parseInt(t,10))).sort(a.L7);for(const h of n){const t=this.nodesByDepth[h];for(const e of t){const t=e.outboundLayer,n=e.inputTensors,o=e.outputTensors,r=new Array;for(const e of n)e.id in s&&r.push(s[e.id]);if(r.length===n.length){let n,u,h,l,c={};if(null!=e.callArgs&&(c=e.callArgs),1===r.length){const[e,s]=r[0];null==c.mask&&(c.mask=s),h=a.zZ(t.call(e,c)),l=a.zZ(t.computeMask(e,s)),n=[e],u=[s]}else n=r.map((t=>t[0])),u=r.map((t=>t[1])),null==c.mask&&(c.mask=u),h=a.zZ(t.call(n,c)),l=a.zZ(t.computeMask(n,u));if(t.activityRegularizer)throw new i.nj("LayersModel invocation with concrete Tensor value(s) in the presence of activity regularizer(s) is not supported yet.");for(let t=0;t<o.length;++t){const e=o[t],n=h[t],i=l[t];s[e.id]=[n,i]}}}}const o=[],r=[],u=[];for(const i of this.outputs){a.hu(i.id in s,`Could not compute output ${i.name} : ${i.id}`);const[t,e]=s[i.id];u.push(t.shape),o.push(t),r.push(e)}return[o,r,u]}buildNodeConversionMap(t){const e={};let s;for(const n of this.layers){s=n instanceof y?1:0;for(let t=0;t<n.inboundNodes.length;t++){const o=y.nodeKey(n,t);this.containerNodes.has(o)&&(e[o]=s,s+=1)}}return e}getLayer(t,e){if(null!=e)return this.findLayer(e);if(null==t)throw new i.nu("Provide either a layer name or layer index");if("number"==typeof t)return this.findLayer(t);for(const s of this.layers)if(s.name===t)return s;throw new i.nu(`No such layer: ${t}`)}findLayer(t){if(this.layers.length<=t)throw new i.nu(`Was asked to retrieve layer at index ${t}, but model only has ${this.layers.length} layer(s).`);return this.layers[t]}calculateLosses(){return(0,n.tidy)((()=>{const t=[];for(const e of this.layers)for(let s=0;s<e.inboundNodes.length;++s){const n=y.nodeKey(e,s);this.containerNodes.has(n)&&t.push(...e.calculateLosses())}return t}))}getConfig(){const t={name:this.name},e=this.buildNodeConversionMap(this.layers),s=[];for(const r of this.layers){const t=r.getClassName(),n=r.getConfig(),o=[];for(let s=0;s<r.inboundNodes.length;s++){const t=r.inboundNodes[s],n=y.nodeKey(r,s);let a={};if(this.containerNodes.has(n)){if(t.callArgs)try{JSON.stringify(t.callArgs),a=t.callArgs}catch(i){console.warn(`Layer ${r.name} was passed non-serializable keyword arguments: ${t.callArgs}. They will not be included in the serialized model (and thus will be missing at deserialization time).`),a={}}if(t.inboundLayers.length>0){const s=[];for(let n=0;n<t.inboundLayers.length;n++){const o=t.inboundLayers[n],i=t.nodeIndices[n],r=t.tensorIndices[n];let u=e[y.nodeKey(o,i)];null==u&&(u=0),s.push([o.name,u,r,a])}o.push(s)}}}const a={};a.name=r.name,a.className=t,a.config=n,a.inboundNodes=o,s.push(a)}t.layers=s;const n=[];for(let r=0;r<this.inputLayers.length;r++){const t=this.inputLayers[r],s=this.inputLayersNodeIndices[r],o=y.nodeKey(t,s);if(!this.containerNodes.has(o))continue;let i=e[o];null==i&&(i=0);const a=this.inputLayersTensorIndices[r];n.push([t.name,i,a])}t.inputLayers=n;const o=[];for(let r=0;r<this.outputLayers.length;r++){const t=this.outputLayers[r],s=this.outputLayersNodeIndices[r],n=y.nodeKey(t,s);if(!this.containerNodes.has(n))continue;let i=e[n];null==i&&(i=0);const a=this.outputLayersTensorIndices[r];o.push([t.name,i,a])}return t.outputLayers=o,t}static fromConfig(t,e,s={},n=!1){const o={},u={};function h(t,e){t.name in u?u[t.name].push(e):u[t.name]=[e]}function l(t,e){const s=[];let n;for(const i of e){const r=i[0],a=i[1],u=i[2];if(n=null==i[3]?{}:i[3],!(r in o))return void h(t,e);const l=o[r];if(l.inboundNodes.length<=a)return void h(t,e);const c=l.inboundNodes[a];s.push(c.outputTensors[u])}s.length>0&&t.apply(a.Bq(s),n)}function c(t){const s=t.name,a=(0,r.v)(t,null!=e.customObjects?e.customObjects:{});a.setFastWeightInitDuringBuild(n),o[s]=a;t.inboundNodes.forEach((t=>{if(!(t instanceof Array))throw new i.nu(`Corrupted configuration, expected array for nodeData: ${t}`);h(a,t)}))}const p=e.name,d=e.layers;for(const i of d)c(i);for(;!a.nK(u);)for(const t of d){const e=o[t.name];if(e.name in u){const t=u[e.name];delete u[e.name];for(const s of t)l(e,s)}}const f=[],y=[],m=e.inputLayers;for(const i of m){const t=i[0],e=i[1],s=i[2];a.hu(t in o);const n=o[t].inboundNodes[e].outputTensors;f.push(n[s])}const g=e.outputLayers;for(const i of g){const t=i[0],e=i[1],s=i[2];a.hu(t in o);const n=o[t].inboundNodes[e].outputTensors;y.push(n[s])}return new t({inputs:f,outputs:y,name:p})}get stateful(){if(this._stateful)throw new i.nu("Container instance unexpectedly has _stateful = true. The statefulness of a Container is determined by the Layers it contains. Its _stateful property must remain the default false.");for(const t of this.layers)if(t.stateful)return!0;return!1}resetStates(){(0,n.tidy)((()=>{this.layers.forEach((t=>{t.stateful&&t.resetStates()}))}))}}}}]);
//# sourceMappingURL=3a2b0ac0-9773c9cebf9262133a83.js.map